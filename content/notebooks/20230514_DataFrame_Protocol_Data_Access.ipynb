{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data from Python's DataFrame Interchange Protocol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependencies for google colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install pyarrow==12.0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's DataFrame interchange protocol specifies a zero-copy data interchange between Python DataFrame libraries, such as [Pandas](https://pandas.pydata.org/), [Vaex](https://vaex.io/), and [Polars](https://polars.rs/). This blog post explores how to read data from the DataFrame [Interchange Protocol](https://data-apis.org/dataframe-protocol/latest/index.html) and perform a simple computation using Python's [ctypes](https://docs.python.org/3/library/ctypes.html) module.  We use Cython to access the data without the GIL and perform the same calculation. This blog post is available as a notebook on [Google Colab](https://colab.research.google.com/github/thomasjpfan/thomasjpfan.github.io/blob/main/content/notebooks/20230514_DataFrame_Protocol_Data_Access.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars DataFrame and the Exchange Protocol\n",
    "\n",
    "First, we create a small DataFrame with a single column and missing values using Polars: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"first\": [None, 1, 2, 3, 8, None, 1, None, 10, -2, -1],\n",
    "    },\n",
    "    schema={\"first\": pl.Int64}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__dataframe__` method of a DataFrame returns an object that implements the DataFrame Interchange Protocol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_protocol = df.__dataframe__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the column from the [API specification](https://data-apis.org/dataframe-protocol/latest/API.html) and access the buffer that contains the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column = df_protocol.get_column_by_name(\"first\")\n",
    "buffer = column.get_buffers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buffer object is a dictionary composed of buffers representing the data and validity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (PyArrowBuffer({'bufsize': 88, 'ptr': 4491764957280, 'device': 'CPU'}),\n",
      "          (<DtypeKind.INT: 0>, 64, 'l', '=')),\n",
      " 'offsets': None,\n",
      " 'validity': (PyArrowBuffer({'bufsize': 2, 'ptr': 4491764629696, 'device': 'CPU'}),\n",
      "              (<DtypeKind.BOOL: 20>, 1, 'b', '='))}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(buffer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'data'` entry consists of the underlying data's buffer and type. We compute the number of items in the buffer by dividing the buffer's size by the data type's size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "buffer_size_in_bits = buffer[\"data\"][0].bufsize * 8\n",
    "buffer_dtype_size = buffer[\"data\"][1][1]\n",
    "n_items = buffer_size_in_bits // buffer_dtype_size\n",
    "print(n_items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [ctypes](https://docs.python.org/3/library/ctypes.html) module, we access the buffer using the pointer address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 8, 0, 1, 0, 10, -2, -1]\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "data = (ctypes.c_int64 * n_items).from_address(buffer[\"data\"][0].ptr)\n",
    "\n",
    "print(list(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array does not give the whole picture of the column. The original column contains null values, represented by a mask stored in the validity buffer. The interchange API tells us that the validity buffer is a bit mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ColumnNullType.USE_BITMASK: 3>, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column.describe_null"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the validity buffer, we see that the buffer size is 2 bytes and the data type has a size of 1 bit, which is consistent with being a bit mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PyArrowBuffer({'bufsize': 2, 'ptr': 4491764629696, 'device': 'CPU'}),\n",
      " (<DtypeKind.BOOL: 20>, 1, 'b', '='))\n"
     ]
    }
   ],
   "source": [
    "pprint(buffer[\"validity\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no `ctypes` that represent one bit of data. However, we can use unsigned 8-bit integers to store the validity buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_items_validity = buffer[\"validity\"][0].bufsize\n",
    "validity = (ctypes.c_uint8 * n_items_validity).from_address(buffer[\"validity\"][0].ptr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 16 bits are enough space to store the bit-mask of the original 11 bits. We use bit-wise operations to access the bit mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1"
     ]
    }
   ],
   "source": [
    "for i in range(n_items):\n",
    "    val_idx = i // 8\n",
    "    val_remainer = i % 8\n",
    "    val = (validity[val_idx] >> val_remainer) & 1\n",
    "\n",
    "    end = \", \" if i < n_items - 1 else \"\"\n",
    "    print(f\"{val}\", end=end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the nan mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data and validity buffer, we can use Python to perform the meanwhile ignoring the null values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75\n"
     ]
    }
   ],
   "source": [
    "def nan_mean(data, validity):\n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        val_idx = i // 8\n",
    "        val_remainder = i % 8\n",
    "        val = (validity[val_idx] >> val_remainder) & 1\n",
    "        if val:\n",
    "            total += data[i]\n",
    "            count += 1\n",
    "    return total / count\n",
    "\n",
    "print(nan_mean(data, validity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is consistent with the value computed using Polars from the original DataFrame, which also ignores the null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌───────┐\n",
      "│ first │\n",
      "│ ---   │\n",
      "│ f64   │\n",
      "╞═══════╡\n",
      "│ 2.75  │\n",
      "└───────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One awesome fact about the `ctype` objects is that they also implement Python's [Buffer Protocol](https://docs.python.org/3/c-api/buffer.html#bufferobjects). With the Buffer Protocol, we can write a Cython function with [memoryviews](http://docs.cython.org/en/latest/src/userguide/memoryviews.html) to perform the nan meanwhile also releasing the GIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def nan_mean_cython(long[::1] array, unsigned char[::1] validity):\n",
    "    cdef:\n",
    "        Py_ssize_t idx, val_idx, val_remainder\n",
    "        double output = 0.0\n",
    "        Py_ssize_t count = 0\n",
    "        \n",
    "    with nogil:\n",
    "        for idx in range(array.shape[0]):\n",
    "            val_idx = idx // 8\n",
    "            val_remainder = idx % 8\n",
    "            if (validity[val_idx] >> val_remainder) & 1:\n",
    "                output += array[idx]\n",
    "                count += 1\n",
    "        \n",
    "    return output / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mean_cython(data, validity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?\n",
    "\n",
    "Python's DataFrame Interchange Protocol provides a uniform API for libraries to write for! In other words, the Cython function above works not only with Polars DataFrames but also with Pandas or Vaex DataFrames. Data access does not require the GIL, so we can release the gil and use native programming languages for acceleration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polars (python3)",
   "language": "python",
   "name": "conda-env-polars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
